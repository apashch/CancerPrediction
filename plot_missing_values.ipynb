{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Imputing missing values before building an estimator\n",
    "\n",
    "\n",
    "Missing values can be replaced by the mean, the median or the most frequent\n",
    "value using the basic :class:`sklearn.impute.SimpleImputer`.\n",
    "The median is a more robust estimator for data with high magnitude variables\n",
    "which could dominate results (otherwise known as a 'long tail').\n",
    "\n",
    "Another option is the :class:`sklearn.impute.IterativeImputer`. This uses\n",
    "round-robin linear regression, treating every variable as an output in\n",
    "turn. The version implemented assumes Gaussian (output) variables. If your\n",
    "features are obviously non-Normal, consider transforming them to look more\n",
    "Normal so as to potentially improve performance.\n",
    "\n",
    "In addition of using an imputing method, we can also keep an indication of the\n",
    "missing information using :func:`sklearn.impute.MissingIndicator` which might\n",
    "carry some information.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn.experimental'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-fd36ca229bfb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# To use the experimental IterativeImputer, we need to explicitly ask for it:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0menable_iterative_imputer\u001b[0m  \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_diabetes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_boston\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn.experimental'"
     ]
    }
   ],
   "source": [
    "print(__doc__)\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# To use the experimental IterativeImputer, we need to explicitly ask for it:\n",
    "import sklearn\n",
    "from sklearn.experimental import enable_iterative_imputer  # noqa\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import make_pipeline, make_union\n",
    "from sklearn.impute import SimpleImputer, IterativeImputer, MissingIndicator\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "rng = np.random.RandomState(0)\n",
    "\n",
    "N_SPLITS = 5\n",
    "REGRESSOR = RandomForestRegressor(random_state=0, n_estimators=100)\n",
    "\n",
    "\n",
    "def get_scores_for_imputer(imputer, X_missing, y_missing):\n",
    "    estimator = make_pipeline(\n",
    "        make_union(imputer, MissingIndicator(missing_values=0)),\n",
    "        REGRESSOR)\n",
    "    impute_scores = cross_val_score(estimator, X_missing, y_missing,\n",
    "                                    scoring='neg_mean_squared_error',\n",
    "                                    cv=N_SPLITS)\n",
    "    return impute_scores\n",
    "\n",
    "\n",
    "def get_results(dataset):\n",
    "    X_full, y_full = dataset.data, dataset.target\n",
    "    n_samples = X_full.shape[0]\n",
    "    n_features = X_full.shape[1]\n",
    "\n",
    "    # Estimate the score on the entire dataset, with no missing values\n",
    "    full_scores = cross_val_score(REGRESSOR, X_full, y_full,\n",
    "                                  scoring='neg_mean_squared_error',\n",
    "                                  cv=N_SPLITS)\n",
    "\n",
    "    # Add missing values in 75% of the lines\n",
    "    missing_rate = 0.75\n",
    "    n_missing_samples = int(np.floor(n_samples * missing_rate))\n",
    "    missing_samples = np.hstack((np.zeros(n_samples - n_missing_samples,\n",
    "                                          dtype=np.bool),\n",
    "                                 np.ones(n_missing_samples,\n",
    "                                         dtype=np.bool)))\n",
    "    rng.shuffle(missing_samples)\n",
    "    missing_features = rng.randint(0, n_features, n_missing_samples)\n",
    "    X_missing = X_full.copy()\n",
    "    X_missing[np.where(missing_samples)[0], missing_features] = 0\n",
    "    y_missing = y_full.copy()\n",
    "\n",
    "    # Estimate the score after replacing missing values by 0\n",
    "    imputer = SimpleImputer(missing_values=0,\n",
    "                            strategy='constant',\n",
    "                            fill_value=0)\n",
    "    zero_impute_scores = get_scores_for_imputer(imputer, X_missing, y_missing)\n",
    "\n",
    "    # Estimate the score after imputation (mean strategy) of the missing values\n",
    "    imputer = SimpleImputer(missing_values=0, strategy=\"mean\")\n",
    "    mean_impute_scores = get_scores_for_imputer(imputer, X_missing, y_missing)\n",
    "\n",
    "    # Estimate the score after iterative imputation of the missing values\n",
    "    imputer = IterativeImputer(missing_values=0,\n",
    "                               random_state=0,\n",
    "                               n_nearest_features=5)\n",
    "    iterative_impute_scores = get_scores_for_imputer(imputer,\n",
    "                                                     X_missing,\n",
    "                                                     y_missing)\n",
    "\n",
    "    return ((full_scores.mean(), full_scores.std()),\n",
    "            (zero_impute_scores.mean(), zero_impute_scores.std()),\n",
    "            (mean_impute_scores.mean(), mean_impute_scores.std()),\n",
    "            (iterative_impute_scores.mean(), iterative_impute_scores.std()))\n",
    "\n",
    "\n",
    "results_diabetes = np.array(get_results(load_diabetes()))\n",
    "mses_diabetes = results_diabetes[:, 0] * -1\n",
    "stds_diabetes = results_diabetes[:, 1]\n",
    "\n",
    "results_boston = np.array(get_results(load_boston()))\n",
    "mses_boston = results_boston[:, 0] * -1\n",
    "stds_boston = results_boston[:, 1]\n",
    "\n",
    "n_bars = len(mses_diabetes)\n",
    "xval = np.arange(n_bars)\n",
    "\n",
    "x_labels = ['Full data',\n",
    "            'Zero imputation',\n",
    "            'Mean Imputation',\n",
    "            'Multivariate Imputation']\n",
    "colors = ['r', 'g', 'b', 'orange']\n",
    "\n",
    "# plot diabetes results\n",
    "plt.figure(figsize=(12, 6))\n",
    "ax1 = plt.subplot(121)\n",
    "for j in xval:\n",
    "    ax1.barh(j, mses_diabetes[j], xerr=stds_diabetes[j],\n",
    "             color=colors[j], alpha=0.6, align='center')\n",
    "\n",
    "ax1.set_title('Imputation Techniques with Diabetes Data')\n",
    "ax1.set_xlim(left=np.min(mses_diabetes) * 0.9,\n",
    "             right=np.max(mses_diabetes) * 1.1)\n",
    "ax1.set_yticks(xval)\n",
    "ax1.set_xlabel('MSE')\n",
    "ax1.invert_yaxis()\n",
    "ax1.set_yticklabels(x_labels)\n",
    "\n",
    "# plot boston results\n",
    "ax2 = plt.subplot(122)\n",
    "for j in xval:\n",
    "    ax2.barh(j, mses_boston[j], xerr=stds_boston[j],\n",
    "             color=colors[j], alpha=0.6, align='center')\n",
    "\n",
    "ax2.set_title('Imputation Techniques with Boston Data')\n",
    "ax2.set_yticks(xval)\n",
    "ax2.set_xlabel('MSE')\n",
    "ax2.invert_yaxis()\n",
    "ax2.set_yticklabels([''] * n_bars)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py37]",
   "language": "python",
   "name": "conda-env-py37-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
