{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49509, 57) (49509, 1)\n",
      "(4578, 1)\n"
     ]
    }
   ],
   "source": [
    "features = pd.read_pickle(\"selected_features.pkl\")\n",
    "target = pd.read_pickle(\"target.pkl\")\n",
    "print(features.shape, target.shape)\n",
    "print(target[target['MCQ220'] == 1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_features = features.values\n",
    "dataset_targets=target.values.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train/test separation\n",
    "perm = np.random.permutation(dataset_targets.shape[0])\n",
    "dataset_features = dataset_features[perm]\n",
    "dataset_targets = dataset_targets[perm]\n",
    "\n",
    "def get_batch(n_size, phase):\n",
    "    # select indices\n",
    "    n_samples = dataset_features.shape[0]\n",
    "    n_classes = int(dataset_targets.max() + 1)\n",
    "    if phase == 'test':\n",
    "        inds_sel = np.arange(0, int(n_samples*0.15), 1)\n",
    "    elif phase == 'validation':\n",
    "        n_samples = dataset_features.shape[0]\n",
    "        inds_sel = np.arange(int(n_samples*0.15), int(n_samples*0.30), 1)\n",
    "    elif phase == 'train':\n",
    "        n_samples = dataset_features.shape[0]\n",
    "        inds_sel = np.arange(int(n_samples*0.30), n_samples, 1)\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "    inds_sel = np.random.permutation(inds_sel)\n",
    "    batch_inds = []\n",
    "    for cl in range(n_classes):\n",
    "        inds_cl = inds_sel[dataset_targets[inds_sel] == cl]\n",
    "        batch_inds.extend(inds_cl[:n_size//n_classes])\n",
    "    batch_inds = np.random.permutation(batch_inds)\n",
    "    \n",
    "    return dataset_features[batch_inds], dataset_targets[batch_inds]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accu_tst_RFC 0.626\n",
      "accu_tst_SVC 0.632\n",
      "accu_tst_LR 0.623\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "features_trn, targets_trn = get_batch(n_size=5000, phase='train')\n",
    "features_tst, targets_tst = get_batch(n_size=1000, phase='test')\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=500)\n",
    "clf.fit(features_trn, targets_trn)\n",
    "preds_tst = clf.predict(features_tst)\n",
    "accu = np.mean(preds_tst==targets_tst)\n",
    "print('accu_tst_RFC', accu)\n",
    "\n",
    "clf = SVC(gamma='auto')\n",
    "clf.fit(features_trn, targets_trn)\n",
    "preds_tst = clf.predict(features_tst)\n",
    "accu = np.mean(preds_tst==targets_tst)\n",
    "print('accu_tst_SVC', accu)\n",
    "\n",
    "clf = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "clf.fit(features_trn, targets_trn)\n",
    "preds_tst = clf.predict(features_tst)\n",
    "accu = np.mean(preds_tst==targets_tst)\n",
    "print('accu_tst_LR', accu)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now trying on larger sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accu_tst_RFC 0.7065514103730665\n",
      "accu_tst_SVC 0.6901728844404004\n",
      "accu_tst_LR 0.697452229299363\n"
     ]
    }
   ],
   "source": [
    "features_trn, targets_trn = get_batch(n_size=15000, phase='train')\n",
    "features_tst, targets_tst = get_batch(n_size=3000, phase='test')\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=500)\n",
    "clf.fit(features_trn, targets_trn)\n",
    "preds_tst_RCL = clf.predict(features_tst)\n",
    "accu = np.mean(preds_tst_RCL==targets_tst)\n",
    "print('accu_tst_RFC', accu)\n",
    "\n",
    "clf = SVC(gamma='auto')\n",
    "clf.fit(features_trn, targets_trn)\n",
    "preds_tst_SVC = clf.predict(features_tst)\n",
    "accu = np.mean(preds_tst_SVC==targets_tst)\n",
    "print('accu_tst_SVC', accu)\n",
    "\n",
    "clf = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "clf.fit(features_trn, targets_trn)\n",
    "preds_tst_LR = clf.predict(features_tst)\n",
    "accu = np.mean(preds_tst_LR==targets_tst)\n",
    "print('accu_tst_LR', accu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try a neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "## using original size of train/test\n",
    "features_trn, targets_trn = get_batch(n_size=15000, phase='train')\n",
    "features_tst, targets_tst = get_batch(n_size=3000, phase='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "10691/10691 [==============================] - 4s 377us/step - loss: 0.5907 - acc: 0.7012\n",
      "Epoch 2/25\n",
      "10691/10691 [==============================] - 4s 346us/step - loss: 0.5768 - acc: 0.7064\n",
      "Epoch 3/25\n",
      "10691/10691 [==============================] - 4s 395us/step - loss: 0.5751 - acc: 0.7114\n",
      "Epoch 4/25\n",
      "10691/10691 [==============================] - 4s 383us/step - loss: 0.5740 - acc: 0.7129\n",
      "Epoch 5/25\n",
      "10691/10691 [==============================] - 4s 387us/step - loss: 0.5728 - acc: 0.7127\n",
      "Epoch 6/25\n",
      "10691/10691 [==============================] - 4s 385us/step - loss: 0.5728 - acc: 0.7083\n",
      "Epoch 7/25\n",
      "10691/10691 [==============================] - 4s 391us/step - loss: 0.5718 - acc: 0.7148\n",
      "Epoch 8/25\n",
      "10691/10691 [==============================] - 4s 390us/step - loss: 0.5728 - acc: 0.7121\n",
      "Epoch 9/25\n",
      "10691/10691 [==============================] - 4s 389us/step - loss: 0.5704 - acc: 0.7140\n",
      "Epoch 10/25\n",
      "10691/10691 [==============================] - 4s 391us/step - loss: 0.5705 - acc: 0.7158\n",
      "Epoch 11/25\n",
      "10691/10691 [==============================] - 4s 388us/step - loss: 0.5692 - acc: 0.7164\n",
      "Epoch 12/25\n",
      "10691/10691 [==============================] - 4s 392us/step - loss: 0.5675 - acc: 0.7145\n",
      "Epoch 13/25\n",
      "10691/10691 [==============================] - 4s 399us/step - loss: 0.5677 - acc: 0.7162\n",
      "Epoch 14/25\n",
      "10691/10691 [==============================] - 5s 448us/step - loss: 0.5665 - acc: 0.7166\n",
      "Epoch 15/25\n",
      "10691/10691 [==============================] - 4s 405us/step - loss: 0.5663 - acc: 0.7163\n",
      "Epoch 16/25\n",
      "10691/10691 [==============================] - 4s 417us/step - loss: 0.5653 - acc: 0.7182\n",
      "Epoch 17/25\n",
      "10691/10691 [==============================] - 5s 432us/step - loss: 0.5638 - acc: 0.7200\n",
      "Epoch 18/25\n",
      "10691/10691 [==============================] - 5s 422us/step - loss: 0.5631 - acc: 0.7188\n",
      "Epoch 19/25\n",
      "10691/10691 [==============================] - 4s 407us/step - loss: 0.5624 - acc: 0.7200\n",
      "Epoch 20/25\n",
      "10691/10691 [==============================] - 4s 410us/step - loss: 0.5626 - acc: 0.7215\n",
      "Epoch 21/25\n",
      "10691/10691 [==============================] - 5s 451us/step - loss: 0.5598 - acc: 0.7201\n",
      "Epoch 22/25\n",
      "10691/10691 [==============================] - 5s 514us/step - loss: 0.5589 - acc: 0.7185\n",
      "Epoch 23/25\n",
      "10691/10691 [==============================] - 5s 425us/step - loss: 0.5591 - acc: 0.7211\n",
      "Epoch 24/25\n",
      "10691/10691 [==============================] - 5s 453us/step - loss: 0.5583 - acc: 0.7216\n",
      "Epoch 25/25\n",
      "10691/10691 [==============================] - 5s 453us/step - loss: 0.5577 - acc: 0.7243\n"
     ]
    }
   ],
   "source": [
    "classifier = Sequential()\n",
    "#First Hidden Layer\n",
    "classifier.add(Dense(16, activation='relu', kernel_initializer='random_normal', input_dim=features_trn.shape[1]))\n",
    "#Second  Hidden Layer\n",
    "classifier.add(Dense(8, activation='relu', kernel_initializer='random_normal'))\n",
    "#Output Layer\n",
    "classifier.add(Dense(1, activation='sigmoid', kernel_initializer='random_normal'))\n",
    "\n",
    "#Compiling the neural network\n",
    "classifier.compile(optimizer ='adam',loss='binary_crossentropy', metrics =['accuracy'])\n",
    "\n",
    "#Fitting the data to the training dataset\n",
    "classifier.fit(features_trn,targets_trn, batch_size=5, epochs=25)\n",
    "\n",
    "#predict on the test set\n",
    "preds_tst=classifier.predict(features_tst)\n",
    "preds_tst_bin =(preds_tst>0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accu_tst_NN 0.6933575978161965\n"
     ]
    }
   ],
   "source": [
    "#measure accuracy\n",
    "accu = np.mean(preds_tst_bin.flatten()==targets_tst)\n",
    "print('accu_tst_NN', accu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.08127615],\n",
       "       [0.52853453],\n",
       "       [0.1401828 ],\n",
       "       ...,\n",
       "       [0.15197423],\n",
       "       [0.22212602],\n",
       "       [0.0986653 ]], dtype=float32)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_tst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 0., ..., 0., 1., 0.])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets_tst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MCQ220</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DMDHRAGE</th>\n",
       "      <td>0.256813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DMQMILIT</th>\n",
       "      <td>0.114839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RIDAGEYR</th>\n",
       "      <td>0.284032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DR1HELPD</th>\n",
       "      <td>0.000660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DR1TKCAL</th>\n",
       "      <td>-0.054950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DR1TM161</th>\n",
       "      <td>-0.044415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DR1TS100</th>\n",
       "      <td>-0.002619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DR1TS140</th>\n",
       "      <td>-0.017791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DR1TSUGR</th>\n",
       "      <td>-0.026063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DR2HELPD</th>\n",
       "      <td>-0.034258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DR2TNIAC</th>\n",
       "      <td>-0.021135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DR2TPROT</th>\n",
       "      <td>-0.027595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BPAEN2</th>\n",
       "      <td>-0.006041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BPXPTY</th>\n",
       "      <td>-0.011231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BPXSY2</th>\n",
       "      <td>0.080311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BPXSY1</th>\n",
       "      <td>0.091065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BPXDI2</th>\n",
       "      <td>-0.045389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BPXDI1</th>\n",
       "      <td>-0.043896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BMXARMC</th>\n",
       "      <td>-0.032102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BMXARML</th>\n",
       "      <td>0.035755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BMXHT</th>\n",
       "      <td>-0.009169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LBXHBS</th>\n",
       "      <td>0.053890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LBDLYMNO</th>\n",
       "      <td>-0.010401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LBDMONO</th>\n",
       "      <td>0.035257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LBDNENO</th>\n",
       "      <td>0.008936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LBXLYPCT</th>\n",
       "      <td>-0.071737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LBXMCHSI</th>\n",
       "      <td>0.057869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LBXMOPCT</th>\n",
       "      <td>0.048892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LBXMPSI</th>\n",
       "      <td>-0.023202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LBXNEPCT</th>\n",
       "      <td>0.049573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LBXRBCSI</th>\n",
       "      <td>-0.073004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LBXRDW</th>\n",
       "      <td>0.045616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LBDSCASI</th>\n",
       "      <td>0.007949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LBDSTPSI</th>\n",
       "      <td>-0.078028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LBXSCA</th>\n",
       "      <td>0.007949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LBXSNASI</th>\n",
       "      <td>0.026687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LBXSTP</th>\n",
       "      <td>-0.078028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BPQ040A</th>\n",
       "      <td>0.011749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HSD010</th>\n",
       "      <td>0.043003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KIQ022</th>\n",
       "      <td>0.055921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MCQ010</th>\n",
       "      <td>0.019034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MCQ160N</th>\n",
       "      <td>0.062735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PAQ620</th>\n",
       "      <td>0.002483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PFQ059</th>\n",
       "      <td>0.030564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HUQ090</th>\n",
       "      <td>0.015954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DR1_WATER</th>\n",
       "      <td>-0.023030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SXQ</th>\n",
       "      <td>-0.025809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RIAGENDR</th>\n",
       "      <td>-0.004893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DMDEDUC2</th>\n",
       "      <td>0.027246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BMXBMI</th>\n",
       "      <td>-0.009033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BMXWT</th>\n",
       "      <td>-0.012683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BMXHT</th>\n",
       "      <td>-0.009169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RIDRETH1#1.0</th>\n",
       "      <td>-0.090596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RIDRETH1#2.0</th>\n",
       "      <td>-0.036652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RIDRETH1#3.0</th>\n",
       "      <td>0.163301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RIDRETH1#4.0</th>\n",
       "      <td>-0.055620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RIDRETH1#5.0</th>\n",
       "      <td>-0.051186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MCQ220</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                MCQ220\n",
       "DMDHRAGE      0.256813\n",
       "DMQMILIT      0.114839\n",
       "RIDAGEYR      0.284032\n",
       "DR1HELPD      0.000660\n",
       "DR1TKCAL     -0.054950\n",
       "DR1TM161     -0.044415\n",
       "DR1TS100     -0.002619\n",
       "DR1TS140     -0.017791\n",
       "DR1TSUGR     -0.026063\n",
       "DR2HELPD     -0.034258\n",
       "DR2TNIAC     -0.021135\n",
       "DR2TPROT     -0.027595\n",
       "BPAEN2       -0.006041\n",
       "BPXPTY       -0.011231\n",
       "BPXSY2        0.080311\n",
       "BPXSY1        0.091065\n",
       "BPXDI2       -0.045389\n",
       "BPXDI1       -0.043896\n",
       "BMXARMC      -0.032102\n",
       "BMXARML       0.035755\n",
       "BMXHT        -0.009169\n",
       "LBXHBS        0.053890\n",
       "LBDLYMNO     -0.010401\n",
       "LBDMONO       0.035257\n",
       "LBDNENO       0.008936\n",
       "LBXLYPCT     -0.071737\n",
       "LBXMCHSI      0.057869\n",
       "LBXMOPCT      0.048892\n",
       "LBXMPSI      -0.023202\n",
       "LBXNEPCT      0.049573\n",
       "LBXRBCSI     -0.073004\n",
       "LBXRDW        0.045616\n",
       "LBDSCASI      0.007949\n",
       "LBDSTPSI     -0.078028\n",
       "LBXSCA        0.007949\n",
       "LBXSNASI      0.026687\n",
       "LBXSTP       -0.078028\n",
       "BPQ040A       0.011749\n",
       "HSD010        0.043003\n",
       "KIQ022        0.055921\n",
       "MCQ010        0.019034\n",
       "MCQ160N       0.062735\n",
       "PAQ620        0.002483\n",
       "PFQ059        0.030564\n",
       "HUQ090        0.015954\n",
       "DR1_WATER    -0.023030\n",
       "SXQ          -0.025809\n",
       "RIAGENDR     -0.004893\n",
       "DMDEDUC2      0.027246\n",
       "BMXBMI       -0.009033\n",
       "BMXWT        -0.012683\n",
       "BMXHT        -0.009169\n",
       "RIDRETH1#1.0 -0.090596\n",
       "RIDRETH1#2.0 -0.036652\n",
       "RIDRETH1#3.0  0.163301\n",
       "RIDRETH1#4.0 -0.055620\n",
       "RIDRETH1#5.0 -0.051186\n",
       "MCQ220        1.000000"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import datawig\n",
    "\n",
    "df = pd.concat([features, target], axis = 1)\n",
    "df = df.reset_index().drop(columns = [\"SEQN\"])\n",
    "\n",
    "df_train, df_test = datawig.utils.random_split(df, split_ratios=[0.8, 0.2])\n",
    "\n",
    "sns.heatmap(df.corr()[['MCQ220']])\n",
    "df.corr()[['MCQ220']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Artem/anaconda/envs/py3tensor/lib/python3.7/site-packages/pandas/core/frame.py:4034: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  downcast=downcast, **kwargs)\n",
      "/Users/Artem/anaconda/envs/py3tensor/lib/python3.7/site-packages/pandas/core/generic.py:6130: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n",
      "/Users/Artem/anaconda/envs/py3tensor/lib/python3.7/site-packages/pandas/core/frame.py:4034: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  downcast=downcast, **kwargs)\n",
      "/Users/Artem/anaconda/envs/py3tensor/lib/python3.7/site-packages/pandas/core/generic.py:6130: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n",
      "2019-06-04 23:30:11,393 [INFO]  \n",
      "========== start: fit model\n",
      "2019-06-04 23:30:11,489 [WARNING]  Already bound, ignoring bind()\n",
      "2019-06-04 23:30:13,352 [INFO]  Epoch[0] Batch [0-1114]\tSpeed: 11222.70 samples/sec\tcross-entropy=15.123111\tMCQ220-accuracy=0.000000\n",
      "2019-06-04 23:30:15,014 [INFO]  Epoch[0] Train-cross-entropy=14.764242\n",
      "2019-06-04 23:30:15,016 [INFO]  Epoch[0] Train-MCQ220-accuracy=0.000000\n",
      "2019-06-04 23:30:15,018 [INFO]  Epoch[0] Time cost=3.523\n",
      "2019-06-04 23:30:15,027 [INFO]  Saved checkpoint to \"imputer_model/model-0000.params\"\n",
      "2019-06-04 23:30:15,220 [INFO]  Epoch[0] Validation-cross-entropy=13.262163\n",
      "2019-06-04 23:30:15,222 [INFO]  Epoch[0] Validation-MCQ220-accuracy=0.000000\n",
      "2019-06-04 23:30:16,795 [INFO]  Epoch[1] Batch [0-1114]\tSpeed: 11366.01 samples/sec\tcross-entropy=14.883634\tMCQ220-accuracy=0.000000\n",
      "2019-06-04 23:30:18,393 [INFO]  Epoch[1] Train-cross-entropy=14.587253\n",
      "2019-06-04 23:30:18,394 [INFO]  Epoch[1] Train-MCQ220-accuracy=0.000000\n",
      "2019-06-04 23:30:18,397 [INFO]  Epoch[1] Time cost=3.172\n",
      "2019-06-04 23:30:18,403 [INFO]  Saved checkpoint to \"imputer_model/model-0001.params\"\n",
      "2019-06-04 23:30:18,588 [INFO]  Epoch[1] Validation-cross-entropy=13.237462\n",
      "2019-06-04 23:30:18,590 [INFO]  Epoch[1] Validation-MCQ220-accuracy=0.000000\n",
      "2019-06-04 23:30:20,155 [INFO]  Epoch[2] Batch [0-1114]\tSpeed: 11424.05 samples/sec\tcross-entropy=14.829786\tMCQ220-accuracy=0.000000\n",
      "2019-06-04 23:30:21,715 [INFO]  Epoch[2] Train-cross-entropy=14.549457\n",
      "2019-06-04 23:30:21,717 [INFO]  Epoch[2] Train-MCQ220-accuracy=0.000000\n",
      "2019-06-04 23:30:21,719 [INFO]  Epoch[2] Time cost=3.126\n",
      "2019-06-04 23:30:21,726 [INFO]  Saved checkpoint to \"imputer_model/model-0002.params\"\n",
      "2019-06-04 23:30:22,116 [INFO]  Epoch[2] Validation-cross-entropy=13.232068\n",
      "2019-06-04 23:30:22,118 [INFO]  Epoch[2] Validation-MCQ220-accuracy=0.000000\n",
      "2019-06-04 23:30:23,790 [INFO]  Epoch[3] Batch [0-1114]\tSpeed: 10691.16 samples/sec\tcross-entropy=14.821427\tMCQ220-accuracy=0.000000\n",
      "2019-06-04 23:30:25,359 [INFO]  Epoch[3] Train-cross-entropy=14.537139\n",
      "2019-06-04 23:30:25,365 [INFO]  Epoch[3] Train-MCQ220-accuracy=0.000000\n",
      "2019-06-04 23:30:25,367 [INFO]  Epoch[3] Time cost=3.247\n",
      "2019-06-04 23:30:25,373 [INFO]  Saved checkpoint to \"imputer_model/model-0003.params\"\n",
      "2019-06-04 23:30:25,764 [INFO]  Epoch[3] Validation-cross-entropy=13.239094\n",
      "2019-06-04 23:30:25,771 [INFO]  Epoch[3] Validation-MCQ220-accuracy=0.000000\n",
      "2019-06-04 23:30:27,398 [INFO]  Epoch[4] Batch [0-1114]\tSpeed: 11060.57 samples/sec\tcross-entropy=14.818217\tMCQ220-accuracy=0.000000\n",
      "2019-06-04 23:30:28,951 [INFO]  Epoch[4] Train-cross-entropy=14.532673\n",
      "2019-06-04 23:30:28,953 [INFO]  Epoch[4] Train-MCQ220-accuracy=0.000000\n",
      "2019-06-04 23:30:28,956 [INFO]  Epoch[4] Time cost=3.178\n",
      "2019-06-04 23:30:28,963 [INFO]  Saved checkpoint to \"imputer_model/model-0004.params\"\n",
      "2019-06-04 23:30:29,131 [INFO]  Epoch[4] Validation-cross-entropy=13.237566\n",
      "2019-06-04 23:30:29,133 [INFO]  Epoch[4] Validation-MCQ220-accuracy=0.000000\n",
      "2019-06-04 23:30:30,998 [INFO]  Epoch[5] Batch [0-1114]\tSpeed: 9576.97 samples/sec\tcross-entropy=14.808965\tMCQ220-accuracy=0.000000\n",
      "2019-06-04 23:30:32,771 [INFO]  Epoch[5] Train-cross-entropy=14.523697\n",
      "2019-06-04 23:30:32,774 [INFO]  Epoch[5] Train-MCQ220-accuracy=0.000000\n",
      "2019-06-04 23:30:32,777 [INFO]  Epoch[5] Time cost=3.642\n",
      "2019-06-04 23:30:32,784 [INFO]  Saved checkpoint to \"imputer_model/model-0005.params\"\n",
      "2019-06-04 23:30:32,986 [INFO]  Epoch[5] Validation-cross-entropy=13.250727\n",
      "2019-06-04 23:30:32,988 [INFO]  Epoch[5] Validation-MCQ220-accuracy=0.000000\n",
      "2019-06-04 23:30:34,722 [INFO]  Epoch[6] Batch [0-1114]\tSpeed: 10309.79 samples/sec\tcross-entropy=14.800377\tMCQ220-accuracy=0.000000\n",
      "2019-06-04 23:30:36,429 [INFO]  Epoch[6] Train-cross-entropy=14.517866\n",
      "2019-06-04 23:30:36,432 [INFO]  Epoch[6] Train-MCQ220-accuracy=0.000000\n",
      "2019-06-04 23:30:36,435 [INFO]  Epoch[6] Time cost=3.444\n",
      "2019-06-04 23:30:36,442 [INFO]  Saved checkpoint to \"imputer_model/model-0006.params\"\n",
      "2019-06-04 23:30:36,791 [INFO]  No improvement detected for 5 epochs compared to 13.237461724348607 last error obtained: 13.249628851730977, stopping here\n",
      "2019-06-04 23:30:36,793 [INFO]  \n",
      "========== done (25.400957822799683 s) fit model\n",
      "/Users/Artem/anaconda/envs/py3tensor/lib/python3.7/site-packages/datawig/calibration.py:92: RuntimeWarning: invalid value encountered in log\n",
      "  return np.log(probas)\n",
      "/Users/Artem/anaconda/envs/py3tensor/lib/python3.7/site-packages/datawig/calibration.py:59: RuntimeWarning: invalid value encountered in greater_equal\n",
      "  bin_mask = (top_probas >= bin_lower) & (top_probas < bin_upper)\n",
      "/Users/Artem/anaconda/envs/py3tensor/lib/python3.7/site-packages/datawig/calibration.py:59: RuntimeWarning: invalid value encountered in less\n",
      "  bin_mask = (top_probas >= bin_lower) & (top_probas < bin_upper)\n",
      "/Users/Artem/anaconda/envs/py3tensor/lib/python3.7/site-packages/pandas/core/frame.py:4034: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  downcast=downcast, **kwargs)\n",
      "/Users/Artem/anaconda/envs/py3tensor/lib/python3.7/site-packages/pandas/core/generic.py:6130: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    }
   ],
   "source": [
    "#Initialize a SimpleImputer model\n",
    "imputer = datawig.SimpleImputer(\n",
    "    #input_columns=list(features.columns), # column(s) containing information about the column we want to impute\n",
    "    input_columns = ['RIDAGEYR', 'DMQMILIT', 'DMDHRAGE'],\n",
    "    output_column='MCQ220', # the column we'd like to impute values for\n",
    "    output_path = 'imputer_model' # stores model data and metrics\n",
    "    )\n",
    "\n",
    "#Fit an imputer model on the train data\n",
    "imputer.fit(train_df=df_train)\n",
    "\n",
    "#Impute missing values and return original dataframe with predictions\n",
    "#predictions, metrics = imputer.transform_and_compute_metrics(df_test)\n",
    "#metrics\n",
    "\n",
    "predictions = imputer.predict(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Columns must be same length as key",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-90-9f7160ca0353>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    123\u001b[0m )\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m \u001b[0mimputer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimputer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/py3tensor/lib/python3.7/site-packages/datawig/imputer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, train_df, test_df, ctx, learning_rate, num_epochs, patience, test_split, weight_decay, batch_size, final_fc_hidden_units, calibrate)\u001b[0m\n\u001b[1;32m    253\u001b[0m             \u001b[0mtrain_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtest_split\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_split\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0miter_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miter_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__build_iterators\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_split\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__check_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/py3tensor/lib/python3.7/site-packages/datawig/imputer.py\u001b[0m in \u001b[0;36m__build_iterators\u001b[0;34m(self, train_df, test_df, test_split)\u001b[0m\n\u001b[1;32m    577\u001b[0m                         encoder_type, \", \".join(encoder.input_columns), len(train_df), encoder.__dict__))\n\u001b[1;32m    578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m                 \u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Building Train Iterator with {} elements\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/py3tensor/lib/python3.7/site-packages/datawig/column_encoders.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, data_frame)\u001b[0m\n\u001b[1;32m    685\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m         \u001b[0mmean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_frame\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_columns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 687\u001b[0;31m         \u001b[0mdata_frame\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_columns\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_frame\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_columns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    688\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_frame\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_columns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/py3tensor/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3365\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setitem_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3366\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3367\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setitem_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3368\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3369\u001b[0m             \u001b[0;31m# set column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/py3tensor/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_setitem_array\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3387\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3388\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3389\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Columns must be same length as key'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3390\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mk1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk2\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3391\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Columns must be same length as key"
     ]
    }
   ],
   "source": [
    "data_encoder_cols = [datawig.NumericalEncoder('DMDHRAGE'), \n",
    "                     datawig.NumericalEncoder('RIDAGEYR'), \n",
    "                     datawig.NumericalEncoder('DR1TKCAL'), \n",
    "                     datawig.NumericalEncoder('DR1TM161'), \n",
    "                     datawig.NumericalEncoder('DR1TS100'), \n",
    "                     datawig.NumericalEncoder('DR1TS140'), \n",
    "                     datawig.NumericalEncoder('DR1TSUGR'), \n",
    "                     datawig.NumericalEncoder('DR2TNIAC'), \n",
    "                     datawig.NumericalEncoder('DR2TPROT'), \n",
    "                     datawig.NumericalEncoder('DR1_WATER'), \n",
    "                     datawig.NumericalEncoder('BPXSY2'), \n",
    "                     datawig.NumericalEncoder('BPXSY1'), \n",
    "                     datawig.NumericalEncoder('BPXDI2'),\n",
    "                     datawig.NumericalEncoder('BPXDI1'),\n",
    "                     datawig.NumericalEncoder('BMXARMC'),\n",
    "                     datawig.NumericalEncoder('BMXARML'),\n",
    "                     datawig.NumericalEncoder('BMXHT'),\n",
    "                     datawig.NumericalEncoder('LBXHBS'),\n",
    "                     datawig.NumericalEncoder('LBDLYMNO'),\n",
    "                     datawig.NumericalEncoder('LBDMONO'),\n",
    "                     datawig.NumericalEncoder('LBDNENO'),\n",
    "                     datawig.NumericalEncoder('LBXLYPCT'),\n",
    "                     datawig.NumericalEncoder('LBXMCHSI'),\n",
    "                     datawig.NumericalEncoder('LBXMOPCT'),\n",
    "                     datawig.NumericalEncoder('LBXMPSI'),\n",
    "                     datawig.NumericalEncoder('LBXNEPCT'),\n",
    "                     datawig.NumericalEncoder('LBXRBCSI'),\n",
    "                     datawig.NumericalEncoder('LBXRDW'),\n",
    "                     datawig.NumericalEncoder('LBDSCASI'),\n",
    "                     datawig.NumericalEncoder('LBDSTPSI'),\n",
    "                     datawig.NumericalEncoder('LBXSCA'),\n",
    "                     datawig.NumericalEncoder('LBXSNASI'),\n",
    "                     datawig.NumericalEncoder('LBXSTP'),\n",
    "                     datawig.NumericalEncoder('HSD010'),\n",
    "                     datawig.NumericalEncoder('BMXBMI'),\n",
    "                     datawig.NumericalEncoder('BMXWT'),\n",
    "                     datawig.NumericalEncoder('BMXHT'),\n",
    "                     datawig.CategoricalEncoder('DMQMILIT'),\n",
    "                     datawig.CategoricalEncoder('DR1HELPD'),\n",
    "                     datawig.CategoricalEncoder('DR2HELPD'),\n",
    "                     datawig.CategoricalEncoder('BPAEN2'),\n",
    "                     datawig.CategoricalEncoder('BPXPTY'),\n",
    "                     datawig.CategoricalEncoder('BPQ040A'),\n",
    "                     datawig.CategoricalEncoder('KIQ022'),\n",
    "                     datawig.CategoricalEncoder('MCQ010'),\n",
    "                     datawig.CategoricalEncoder('MCQ160N'),\n",
    "                     datawig.CategoricalEncoder('PAQ620'),\n",
    "                     datawig.CategoricalEncoder('PFQ059'),\n",
    "                     datawig.CategoricalEncoder('HUQ090'),\n",
    "                     datawig.CategoricalEncoder('SXQ'),\n",
    "                     datawig.CategoricalEncoder('RIDRETH1#1.0'),\n",
    "                     datawig.CategoricalEncoder('RIDRETH1#2.0'),\n",
    "                     datawig.CategoricalEncoder('RIDRETH1#3.0'),\n",
    "                     datawig.CategoricalEncoder('RIDRETH1#4.0'),\n",
    "                     datawig.CategoricalEncoder('RIDRETH1#5.0')\n",
    "                    ]\n",
    "\n",
    "\n",
    "data_featurizer_cols = [datawig.NumericalFeaturizer('DMDHRAGE'), \n",
    "                     datawig.NumericalFeaturizer('RIDAGEYR'), \n",
    "                     datawig.NumericalFeaturizer('DR1TKCAL'), \n",
    "                     datawig.NumericalFeaturizer('DR1TM161'), \n",
    "                     datawig.NumericalFeaturizer('DR1TS100'), \n",
    "                     datawig.NumericalFeaturizer('DR1TS140'), \n",
    "                     datawig.NumericalFeaturizer('DR1TSUGR'), \n",
    "                     datawig.NumericalFeaturizer('DR2TNIAC'), \n",
    "                     datawig.NumericalFeaturizer('DR2TPROT'), \n",
    "                     datawig.NumericalFeaturizer('DR1_WATER'), \n",
    "                     datawig.NumericalFeaturizer('BPXSY2'), \n",
    "                     datawig.NumericalFeaturizer('BPXSY1'), \n",
    "                     datawig.NumericalFeaturizer('BPXDI2'),\n",
    "                     datawig.NumericalFeaturizer('BPXDI1'),\n",
    "                     datawig.NumericalFeaturizer('BMXARMC'),\n",
    "                     datawig.NumericalFeaturizer('BMXARML'),\n",
    "                     datawig.NumericalFeaturizer('BMXHT'),\n",
    "                     datawig.NumericalFeaturizer('LBXHBS'),\n",
    "                     datawig.NumericalFeaturizer('LBDLYMNO'),\n",
    "                     datawig.NumericalFeaturizer('LBDMONO'),\n",
    "                     datawig.NumericalFeaturizer('LBDNENO'),\n",
    "                     datawig.NumericalFeaturizer('LBXLYPCT'),\n",
    "                     datawig.NumericalFeaturizer('LBXMCHSI'),\n",
    "                     datawig.NumericalFeaturizer('LBXMOPCT'),\n",
    "                     datawig.NumericalFeaturizer('LBXMPSI'),\n",
    "                     datawig.NumericalFeaturizer('LBXNEPCT'),\n",
    "                     datawig.NumericalFeaturizer('LBXRBCSI'),\n",
    "                     datawig.NumericalFeaturizer('LBXRDW'),\n",
    "                     datawig.NumericalFeaturizer('LBDSCASI'),\n",
    "                     datawig.NumericalFeaturizer('LBDSTPSI'),\n",
    "                     datawig.NumericalFeaturizer('LBXSCA'),\n",
    "                     datawig.NumericalFeaturizer('LBXSNASI'),\n",
    "                     datawig.NumericalFeaturizer('LBXSTP'),\n",
    "                     datawig.NumericalFeaturizer('HSD010'),\n",
    "                     datawig.NumericalFeaturizer('BMXBMI'),\n",
    "                     datawig.NumericalFeaturizer('BMXWT'),\n",
    "                     datawig.NumericalFeaturizer('BMXHT'),\n",
    "                     datawig.EmbeddingFeaturizer('DMQMILIT'),\n",
    "                     datawig.EmbeddingFeaturizer('DR1HELPD'),\n",
    "                     datawig.EmbeddingFeaturizer('DR2HELPD'),\n",
    "                     datawig.EmbeddingFeaturizer('BPAEN2'),\n",
    "                     datawig.EmbeddingFeaturizer('BPXPTY'),\n",
    "                     datawig.EmbeddingFeaturizer('BPQ040A'),\n",
    "                     datawig.EmbeddingFeaturizer('KIQ022'),\n",
    "                     datawig.EmbeddingFeaturizer('MCQ010'),\n",
    "                     datawig.EmbeddingFeaturizer('MCQ160N'),\n",
    "                     datawig.EmbeddingFeaturizer('PAQ620'),\n",
    "                     datawig.EmbeddingFeaturizer('PFQ059'),\n",
    "                     datawig.EmbeddingFeaturizer('HUQ090'),\n",
    "                     datawig.EmbeddingFeaturizer('SXQ'),\n",
    "                     datawig.EmbeddingFeaturizer('RIDRETH1#1.0'),\n",
    "                     datawig.EmbeddingFeaturizer('RIDRETH1#2.0'),\n",
    "                     datawig.EmbeddingFeaturizer('RIDRETH1#3.0'),\n",
    "                     datawig.EmbeddingFeaturizer('RIDRETH1#4.0'),\n",
    "                     datawig.EmbeddingFeaturizer('RIDRETH1#5.0')\n",
    "                    ]\n",
    "label_encoder_cols = [datawig.CategoricalEncoder('MCQ220')]\n",
    "\n",
    "imputer = datawig.Imputer(\n",
    "    data_featurizers=data_featurizer_cols,\n",
    "    label_encoders=label_encoder_cols,\n",
    "    data_encoders=data_encoder_cols,\n",
    "    output_path='imputer_model'\n",
    ")\n",
    "\n",
    "imputer.fit(train_df=df_train)\n",
    "predictions = imputer.predict(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55 55\n"
     ]
    }
   ],
   "source": [
    "print(len(data_encoder_cols),len(data_featurizer_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    9901.0\n",
       "mean        0.0\n",
       "std         0.0\n",
       "min         0.0\n",
       "25%         0.0\n",
       "50%         0.0\n",
       "75%         0.0\n",
       "max         0.0\n",
       "Name: MCQ220_imputed, dtype: float64"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions['MCQ220_imputed'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['DMDHRAGE', 'DMQMILIT', 'RIDAGEYR', 'DR1HELPD', 'DR1TKCAL', 'DR1TM161',\n",
       "       'DR1TS100', 'DR1TS140', 'DR1TSUGR', 'DR2HELPD', 'DR2TNIAC', 'DR2TPROT',\n",
       "       'BPAEN2', 'BPXPTY', 'BPXSY2', 'BPXSY1', 'BPXDI2', 'BPXDI1', 'BMXARMC',\n",
       "       'BMXARML', 'BMXHT', 'LBXHBS', 'LBDLYMNO', 'LBDMONO', 'LBDNENO',\n",
       "       'LBXLYPCT', 'LBXMCHSI', 'LBXMOPCT', 'LBXMPSI', 'LBXNEPCT', 'LBXRBCSI',\n",
       "       'LBXRDW', 'LBDSCASI', 'LBDSTPSI', 'LBXSCA', 'LBXSNASI', 'LBXSTP',\n",
       "       'BPQ040A', 'HSD010', 'KIQ022', 'MCQ010', 'MCQ160N', 'PAQ620', 'PFQ059',\n",
       "       'HUQ090', 'DR1_WATER', 'SXQ', 'RIAGENDR', 'DMDEDUC2', 'BMXBMI', 'BMXWT',\n",
       "       'BMXHT', 'RIDRETH1#1.0', 'RIDRETH1#2.0', 'RIDRETH1#3.0', 'RIDRETH1#4.0',\n",
       "       'RIDRETH1#5.0', 'MCQ220'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Simple Voter based on 4 high performing prediction algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2198,)\n",
      "(2198,)\n",
      "(2198,)\n",
      "(2198,)\n"
     ]
    }
   ],
   "source": [
    "print(preds_tst_RCL.flatten().shape)\n",
    "print(preds_tst_SVC.flatten().shape)\n",
    "print(preds_tst_LR.flatten().shape)\n",
    "print(preds_tst_bin.flatten().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accu_tst_ensemble 0.7015468607825296\n"
     ]
    }
   ],
   "source": [
    "pred = 0.25*(1.001*preds_tst_RCL.flatten() + preds_tst_SVC.flatten() + preds_tst_LR.flatten() + preds_tst_bin.flatten())\n",
    "pred_bin = pred>=0.5\n",
    "accu = np.mean(pred_bin==targets_tst)\n",
    "print('accu_tst_ensemble', accu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.94      0.81      1500\n",
      "         1.0       0.59      0.20      0.30       698\n",
      "\n",
      "    accuracy                           0.70      2198\n",
      "   macro avg       0.65      0.57      0.55      2198\n",
      "weighted avg       0.68      0.70      0.65      2198\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.94      0.81      1500\n",
      "         1.0       0.62      0.20      0.30       698\n",
      "\n",
      "    accuracy                           0.71      2198\n",
      "   macro avg       0.67      0.57      0.56      2198\n",
      "weighted avg       0.69      0.71      0.65      2198\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.70      0.95      0.81      1500\n",
      "         1.0       0.55      0.14      0.22       698\n",
      "\n",
      "    accuracy                           0.69      2198\n",
      "   macro avg       0.63      0.54      0.51      2198\n",
      "weighted avg       0.65      0.69      0.62      2198\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.71      0.93      0.81      1500\n",
      "         1.0       0.57      0.19      0.28       698\n",
      "\n",
      "    accuracy                           0.70      2198\n",
      "   macro avg       0.64      0.56      0.55      2198\n",
      "weighted avg       0.67      0.70      0.64      2198\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.71      0.93      0.81      1500\n",
      "         1.0       0.55      0.18      0.27       698\n",
      "\n",
      "    accuracy                           0.69      2198\n",
      "   macro avg       0.63      0.56      0.54      2198\n",
      "weighted avg       0.66      0.69      0.64      2198\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(targets_tst, pred_bin))\n",
    "print(classification_report(targets_tst, preds_tst_RCL.flatten()))\n",
    "print(classification_report(targets_tst, preds_tst_SVC.flatten()))\n",
    "print(classification_report(targets_tst, preds_tst_LR.flatten()))\n",
    "print(classification_report(targets_tst, preds_tst_bin.flatten()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accu_tst_RFC 0.6075\n",
      "accu_tst_SVC 0.61\n",
      "accu_tst_LR 0.585\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.60      0.62      0.61       200\n",
      "         1.0       0.61      0.59      0.60       200\n",
      "\n",
      "    accuracy                           0.61       400\n",
      "   macro avg       0.61      0.61      0.61       400\n",
      "weighted avg       0.61      0.61      0.61       400\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.60      0.64      0.62       200\n",
      "         1.0       0.62      0.58      0.60       200\n",
      "\n",
      "    accuracy                           0.61       400\n",
      "   macro avg       0.61      0.61      0.61       400\n",
      "weighted avg       0.61      0.61      0.61       400\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.58      0.59      0.59       200\n",
      "         1.0       0.59      0.58      0.58       200\n",
      "\n",
      "    accuracy                           0.58       400\n",
      "   macro avg       0.59      0.58      0.58       400\n",
      "weighted avg       0.59      0.58      0.58       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "features_trn2, targets_trn2 = get_batch(n_size=4000, phase='train')\n",
    "features_tst2, targets_tst2 = get_batch(n_size=400, phase='test')\n",
    "\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=500)\n",
    "clf.fit(features_trn2, targets_trn2)\n",
    "preds_tst_RCL = clf.predict(features_tst2)\n",
    "accu = np.mean(preds_tst_RCL==targets_tst2)\n",
    "print('accu_tst_RFC', accu)\n",
    "\n",
    "clf = SVC(gamma='auto')\n",
    "clf.fit(features_trn2, targets_trn2)\n",
    "preds_tst_SVC = clf.predict(features_tst2)\n",
    "accu = np.mean(preds_tst_SVC==targets_tst2)\n",
    "print('accu_tst_SVC', accu)\n",
    "\n",
    "clf = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "clf.fit(features_trn2, targets_trn2)\n",
    "preds_tst_LR = clf.predict(features_tst2)\n",
    "accu = np.mean(preds_tst_LR==targets_tst2)\n",
    "print('accu_tst_LR', accu)\n",
    "\n",
    "\n",
    "print(classification_report(targets_tst2, preds_tst_RCL.flatten()))\n",
    "print(classification_report(targets_tst2, preds_tst_SVC.flatten()))\n",
    "print(classification_report(targets_tst2, preds_tst_LR.flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "4000/4000 [==============================] - 2s 615us/step - loss: 0.6860 - acc: 0.5590\n",
      "Epoch 2/20\n",
      "4000/4000 [==============================] - 2s 402us/step - loss: 0.6665 - acc: 0.6205\n",
      "Epoch 3/20\n",
      "4000/4000 [==============================] - 2s 395us/step - loss: 0.6563 - acc: 0.6283\n",
      "Epoch 4/20\n",
      "4000/4000 [==============================] - 2s 399us/step - loss: 0.6499 - acc: 0.6323\n",
      "Epoch 5/20\n",
      "4000/4000 [==============================] - 2s 392us/step - loss: 0.6462 - acc: 0.6365\n",
      "Epoch 6/20\n",
      "4000/4000 [==============================] - 2s 471us/step - loss: 0.6434 - acc: 0.6388\n",
      "Epoch 7/20\n",
      "4000/4000 [==============================] - 2s 454us/step - loss: 0.6430 - acc: 0.6398\n",
      "Epoch 8/20\n",
      "4000/4000 [==============================] - 2s 429us/step - loss: 0.6405 - acc: 0.6443\n",
      "Epoch 9/20\n",
      "4000/4000 [==============================] - 2s 408us/step - loss: 0.6379 - acc: 0.6435\n",
      "Epoch 10/20\n",
      "4000/4000 [==============================] - 2s 404us/step - loss: 0.6373 - acc: 0.6450\n",
      "Epoch 11/20\n",
      "4000/4000 [==============================] - 2s 422us/step - loss: 0.6353 - acc: 0.6450\n",
      "Epoch 12/20\n",
      "4000/4000 [==============================] - 2s 503us/step - loss: 0.6353 - acc: 0.6438\n",
      "Epoch 13/20\n",
      "4000/4000 [==============================] - 2s 438us/step - loss: 0.6338 - acc: 0.6525\n",
      "Epoch 14/20\n",
      "4000/4000 [==============================] - 2s 424us/step - loss: 0.6329 - acc: 0.6468\n",
      "Epoch 15/20\n",
      "4000/4000 [==============================] - 2s 418us/step - loss: 0.6327 - acc: 0.6490\n",
      "Epoch 16/20\n",
      "4000/4000 [==============================] - 2s 413us/step - loss: 0.6309 - acc: 0.6488\n",
      "Epoch 17/20\n",
      "4000/4000 [==============================] - 2s 482us/step - loss: 0.6316 - acc: 0.6525\n",
      "Epoch 18/20\n",
      "4000/4000 [==============================] - 2s 560us/step - loss: 0.6303 - acc: 0.6448\n",
      "Epoch 19/20\n",
      "4000/4000 [==============================] - 2s 545us/step - loss: 0.6280 - acc: 0.6573\n",
      "Epoch 20/20\n",
      "4000/4000 [==============================] - 2s 413us/step - loss: 0.6281 - acc: 0.6510\n"
     ]
    }
   ],
   "source": [
    "classifier = Sequential()\n",
    "#First Hidden Layer\n",
    "classifier.add(Dense(16, activation='relu', kernel_initializer='random_normal', input_dim=features_trn2.shape[1]))\n",
    "#Second  Hidden Layer\n",
    "classifier.add(Dense(8, activation='relu', kernel_initializer='random_normal'))\n",
    "#Output Layer\n",
    "classifier.add(Dense(1, activation='sigmoid', kernel_initializer='random_normal'))\n",
    "\n",
    "#Compiling the neural network\n",
    "classifier.compile(optimizer ='adam',loss='binary_crossentropy', metrics =['accuracy'])\n",
    "\n",
    "#Fitting the data to the training dataset\n",
    "classifier.fit(features_trn2,targets_trn2, batch_size=5, epochs=20)\n",
    "\n",
    "#predict on the test set\n",
    "preds_tst=classifier.predict(features_tst2)\n",
    "preds_tst_bin =(preds_tst>0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accu_tst_NN 0.5925\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.58      0.67      0.62       200\n",
      "         1.0       0.61      0.52      0.56       200\n",
      "\n",
      "    accuracy                           0.59       400\n",
      "   macro avg       0.59      0.59      0.59       400\n",
      "weighted avg       0.59      0.59      0.59       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#measure accuracy\n",
    "accu = np.mean(preds_tst_bin.flatten()==targets_tst2)\n",
    "print('accu_tst_NN', accu)\n",
    "print(classification_report(targets_tst2, preds_tst_bin.flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py3tensor]",
   "language": "python",
   "name": "conda-env-py3tensor-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
