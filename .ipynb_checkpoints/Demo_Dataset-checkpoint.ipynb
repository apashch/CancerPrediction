{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pdb\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import nhanes as nhanes\n",
    "\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_PATH = '/Users/Artem/Documents/CS\\ 205/NHANES/'\n",
    "DATASET = 'arthritis'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note: \n",
    "The code below loads each dataset: dataset_features, dataset_targets\n",
    "\n",
    "Here, all datasets are defined explicitly (see nhanes.py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: BPQ_B.XPT"
     ]
    }
   ],
   "source": [
    "ds = nhanes.Dataset(DATA_PATH)\n",
    "ds.load_arthritis()\n",
    "n_fe = ds.features.shape[1]\n",
    "n_classes = 2\n",
    "\n",
    "dataset_features = ds.features\n",
    "dataset_targets = ds.targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Test Separation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "perm = np.random.permutation(dataset_targets.shape[0])\n",
    "dataset_features = dataset_features[perm]\n",
    "dataset_targets = dataset_targets[perm]\n",
    "\n",
    "def get_batch(n_size, phase):\n",
    "    # select indices\n",
    "    n_samples = dataset_features.shape[0]\n",
    "    n_classes = int(dataset_targets.max() + 1)\n",
    "    if phase == 'test':\n",
    "        inds_sel = np.arange(0, int(n_samples*0.15), 1)\n",
    "    elif phase == 'validation':\n",
    "        n_samples = dataset_features.shape[0]\n",
    "        inds_sel = np.arange(int(n_samples*0.15), int(n_samples*0.30), 1)\n",
    "    elif phase == 'train':\n",
    "        n_samples = dataset_features.shape[0]\n",
    "        inds_sel = np.arange(int(n_samples*0.30), n_samples, 1)\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "    inds_sel = np.random.permutation(inds_sel)\n",
    "    batch_inds = []\n",
    "    for cl in range(n_classes):\n",
    "        inds_cl = inds_sel[dataset_targets[inds_sel] == cl]\n",
    "        batch_inds.extend(inds_cl[:n_size//n_classes])\n",
    "    batch_inds = np.random.permutation(batch_inds)\n",
    "    \n",
    "    return dataset_features[batch_inds], dataset_targets[batch_inds]\n",
    "    \n",
    "features_trn, targets_trn = get_batch(n_size=5000, phase='train')\n",
    "features_tst, targets_tst = get_batch(n_size=1000, phase='test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accu_tst_RFC 0.736\n",
      "accu_tst_SVC 0.738\n",
      "accu_tst_LR 0.743\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "clf.fit(features_trn, targets_trn)\n",
    "preds_tst = clf.predict(features_tst)\n",
    "accu = np.mean(preds_tst==targets_tst)\n",
    "print('accu_tst_RFC', accu)\n",
    "\n",
    "clf = SVC(gamma='auto')\n",
    "clf.fit(features_trn, targets_trn)\n",
    "preds_tst = clf.predict(features_tst)\n",
    "accu = np.mean(preds_tst==targets_tst)\n",
    "print('accu_tst_SVC', accu)\n",
    "\n",
    "clf = LogisticRegression(solver='lbfgs', max_iter=200)\n",
    "clf.fit(features_trn, targets_trn)\n",
    "preds_tst = clf.predict(features_tst)\n",
    "accu = np.mean(preds_tst==targets_tst)\n",
    "print('accu_tst_LR', accu)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
